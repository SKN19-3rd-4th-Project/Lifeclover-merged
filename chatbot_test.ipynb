{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb4d11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c207cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX_HOST = \"https://funeral-index-wb03sz2.svc.aped-4627-b74a.pinecone.io\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback # ìƒì„¸ ì—ëŸ¬ í™•ì¸ì„ ìœ„í•´ ì¶”ê°€\n",
    "import os\n",
    "\n",
    "@tool\n",
    "def search_columbarium(query: str, region: str = None):\n",
    "    \"\"\"\n",
    "    ë´‰ì•ˆë‹¹ ë˜ëŠ” ë‚©ê³¨ë‹¹ì„ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        query (str): ê²€ìƒ‰í•  ì§ˆë¬¸ ë‚´ìš© (ì˜ˆ: \"ì‹œì„¤ ì¢‹ì€ ë´‰ì•ˆë‹¹\")\n",
    "        region (str, optional): ì‚¬ìš©ìê°€ íŠ¹ì • ì§€ì—­ì„ ì–¸ê¸‰í•œ ê²½ìš° í•´ë‹¹ ì§€ì—­ëª….\n",
    "                                ë°ì´í„°ë² ì´ìŠ¤ì˜ ì§€ì—­ëª…ì€ 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì¶©ì²­ë¶ë„' ë“± ê´‘ì—­ìì¹˜ë‹¨ì²´ ëª…ì¹­ì…ë‹ˆë‹¤.\n",
    "                                ì‚¬ìš©ìê°€ 'ë¶€ì‚°'ì´ë¼ê³  í•˜ë©´ 'ë¶€ì‚°ê´‘ì—­ì‹œ'ë¡œ, 'ì¶©ë¶'ì´ë¼ê³  í•˜ë©´ 'ì¶©ì²­ë¶ë„'ë¡œ ë³€í™˜í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: {query}, ì§€ì—­í•„í„°: {region}\")\n",
    "    \n",
    "    # 1. ì—°ê²° ì„¤ì •\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "    index = pc.Index(host=os.environ.get(\"PINECONE_INDEX_HOST\"))\n",
    "    vectorstore = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "    \n",
    "    # 2. ë©”íƒ€ë°ì´í„° í•„í„° ìƒì„±\n",
    "    # Pinecone í•„í„° ë¬¸ë²•: {'meta_key': {'$eq': 'value'}}\n",
    "    filter_dict = {}\n",
    "    if region:\n",
    "        filter_dict[\"region\"] = {\"$eq\": region}\n",
    "        print(f\"âœ… ì§€ì—­ í•„í„° ì ìš©ë¨: {region}\")\n",
    "    \n",
    "    # 3. í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ê²€ìƒ‰\n",
    "    try:\n",
    "        results = vectorstore.similarity_search(\n",
    "            query, \n",
    "            k=3,\n",
    "            filter=filter_dict  # ì—¬ê¸°ì— í•„í„°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "\n",
    "    # 4. ê²°ê³¼ ë°˜í™˜\n",
    "    if not results:\n",
    "        return \"í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì‹œì„¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    formatted_results = \"\"\n",
    "    for i, doc in enumerate(results):\n",
    "        formatted_results += f\"\\n[ê²°ê³¼ {i+1}]\\n\"\n",
    "        formatted_results += f\"ì´ë¦„: {doc.metadata.get('name')}\\n\"\n",
    "        formatted_results += f\"ì§€ì—­: {doc.metadata.get('region')} {doc.metadata.get('location')}\\n\"\n",
    "        formatted_results += f\"ì£¼ì†Œ: {doc.metadata.get('address')}\\n\"\n",
    "        formatted_results += f\"ì „í™”ë²ˆí˜¸: {doc.metadata.get('phone')}\\n\"\n",
    "    \n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangGraph ìƒíƒœ ë° ë…¸ë“œ ì •ì˜\n",
    "tools = [search_columbarium]\n",
    "\n",
    "# LLM ëª¨ë¸ ë¡œë“œ ë° ë„êµ¬ ë°”ì¸ë”©\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.1)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# ê·¸ë˜í”„ì˜ State ì •ì˜ (ëŒ€í™” ê¸°ë¡ ìœ ì§€)\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def agent_node(state: AgentState):\n",
    "    # í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜´\n",
    "    current_messages = state['messages']\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "    system_prompt = SystemMessage(content=\"\"\"\n",
    "    ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì‚¬ë ¤ ê¹Šì€ 'ì¥ì‚¬ ì •ë³´ ì•ˆë‚´ ë„ìš°ë¯¸'ì…ë‹ˆë‹¤.\n",
    "    ì‚¬ìš©ìê°€ ì¥ë¡€ì‹ì¥, ë´‰ì•ˆë‹¹, ë‚©ê³¨ë‹¹ ë“±ì˜ ì •ë³´ë¥¼ ë¬»ê±°ë‚˜, ì£½ìŒ/ì„ì¢…/ë¹ˆì†Œ/ì¡°ë¬¸ ë“±ê³¼ ê´€ë ¨ëœ ìƒí™©ì„ ì•”ì‹œí•˜ë©´ \n",
    "    ë°˜ë“œì‹œ 'search_columbarium' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ ì¥ì†Œë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.\n",
    "    \n",
    "    ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì§€ì—­ì„ ë§í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ë¨¼ì € ì–´ëŠ ì§€ì—­ì„ ì°¾ëŠ”ì§€ ì •ì¤‘í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.\n",
    "    ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ì œê³µí•  ë•ŒëŠ” ìœ„ë¡œì˜ ë§ê³¼ í•¨ê»˜ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”.\n",
    "    \"\"\")\n",
    "\n",
    "    # ëŒ€í™” ê¸°ë¡ ë§¨ ì•ì— ì‹œìŠ¤í…œ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´, ì´ë²ˆ í„´(invoke)ì—ë§Œ ì„ì‹œë¡œ ë¶™ì—¬ì„œ ë³´ëƒ„\n",
    "    # (stateì— ì˜êµ¬ ì €ì¥í•˜ì§€ ì•ŠìŒìœ¼ë¡œì¨ ì¤‘ë³µ ë°©ì§€)\n",
    "    if not isinstance(current_messages[0], SystemMessage):\n",
    "        messages_to_send = [system_prompt] + current_messages\n",
    "    else:\n",
    "        messages_to_send = current_messages\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = llm_with_tools.invoke(messages_to_send)\n",
    "    print(\"response:\", response)\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ì‘ë‹µë§Œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ ë°˜í™˜ (add_messagesê°€ ì•Œì•„ì„œ ê¸°ì¡´ ê¸°ë¡ ë’¤ì— ë¶™ì—¬ì¤Œ)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# [Node 2] ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# [Edge] ì¡°ê±´ë¶€ ì—£ì§€: ë„êµ¬ë¥¼ ì“¸ì§€, ë‹µë³€ì„ ëë‚¼ì§€ ê²°ì •\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    print(f\"Tool Calls ì¡´ì¬ ì—¬ë¶€: {last_message.tool_calls}\")\n",
    "    \n",
    "    # LLMì´ ë„êµ¬ í˜¸ì¶œì„ ìš”ì²­í–ˆëŠ”ì§€ í™•ì¸\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b00d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ê·¸ë˜í”„ êµ¬ì„± (Workflow)\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²°\n",
    "workflow.set_entry_point(\"agent\") # ì‹œì‘ì \n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\") # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì—ì´ì „íŠ¸ë¡œ ë³µê·€ (ê²°ê³¼ í•´ì„)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "050de4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "def chat(user_input):\n",
    "    print(f\"\\nì‚¬ìš©ì: {user_input}\")\n",
    "    inputs = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "    \n",
    "    # ê·¸ë˜í”„ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê³¼ì • í™•ì¸ ê°€ëŠ¥)\n",
    "    for event in app.stream(inputs):\n",
    "        for key, value in event.items():\n",
    "            if key == \"agent\":\n",
    "                msg = value[\"messages\"][0]\n",
    "                print(f\"Agent ìƒê°: {msg.content}\") # ë””ë²„ê¹…ìš©\n",
    "            elif key == \"tools\":\n",
    "                # print(f\"Tool ì‹¤í–‰ ê²°ê³¼...\") # ë””ë²„ê¹…ìš©\n",
    "                pass\n",
    "    \n",
    "    # ìµœì¢… ì‘ë‹µ ì¶œë ¥\n",
    "    final_response = value[\"messages\"][0].content\n",
    "    print(f\"ì±—ë´‡: {final_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea9dcbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20542386",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ì¼€ì´ìŠ¤ 1: ì§ì ‘ì ì¸ ìš”ì²­\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mchat\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mê²½ë‚¨ ìª½ ì¥ë¡€ì‹ì¥ì„ ì•Œë ¤ì¤˜.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'chat' is not defined"
     ]
    }
   ],
   "source": [
    "# ì¼€ì´ìŠ¤ 1: ì§ì ‘ì ì¸ ìš”ì²­\n",
    "chat(\"ì„œìš¸ì— ìˆëŠ” ë´‰ì•ˆë‹¹ì„ ì•Œë ¤ì¤˜.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabc0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # ì¼€ì´ìŠ¤ 2: ì•”ì‹œì ì¸ ìƒí™© (ë„êµ¬ í˜¸ì¶œ ì „ ì§€ì—­ í™•ì¸ ìœ ë„ ì˜ˆìƒ)\n",
    "# chat(\"ê°‘ìê¸° ì•„ë²„ì§€ê°€ ëŒì•„ê°€ì…¨ì–´.. ì–´ë–¡í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ë„¤.\")\n",
    "\n",
    "# # ì¼€ì´ìŠ¤ 3: ì•”ì‹œì  ìƒí™© + ì§€ì—­ í¬í•¨\n",
    "# chat(\"ì§€ê¸ˆ ë¶€ì‚° í•´ìš´ëŒ€ ìª½ì¸ë°, ê¸‰í•˜ê²Œ ë¹ˆì†Œë¥¼ ì•Œì•„ë´ì•¼ í•´.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e39e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat(\"ë¶€ì‚°ê´‘ì—­ì‹œì— ìˆëŠ” ë´‰ì•ˆë‹¹ì„ ì•Œë ¤ì¤˜\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
